## í•œê¸€ê³¼ ìˆ«ìì¸ì‹ ... ë²ˆí˜¸íŒì´ ì¸ì‹ì•ˆë¨
import sys
import torch
import easyocr
import cv2
import numpy as np
import re  # ì •ê·œì‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
from PyQt5.QtWidgets import QApplication, QWidget, QLabel, QVBoxLayout, QListWidget
from PyQt5.QtGui import QPixmap, QImage
from PyQt5.QtCore import QTimer, QThread, pyqtSignal


class LicensePlateRecognitionApp(QWidget):
    def __init__(self):
        super().__init__()

        self.initUI()

        # YOLOv5 ëª¨ë¸ ë¡œë“œ
        self.model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)
        # EasyOCR ëª¨ë¸ ë¡œë“œ
        self.reader = easyocr.Reader(['ko', 'en'], gpu=False)

        # ì¹´ë©”ë¼ ìº¡ì²˜
        self.cap = cv2.VideoCapture(0)  # ê¸°ë³¸ ì¹´ë©”ë¼
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)  # í•´ìƒë„ ì¦ê°€
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

        # ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ ìŠ¤ë ˆë“œ ìƒì„±
        self.thread = VideoCaptureThread(self.cap)
        self.thread.change_pixmap_signal.connect(self.update_image)
        self.thread.start()

        # íƒ€ì´ë¨¸ë¥¼ ì„¤ì •í•˜ì—¬ ì‹¤ì‹œê°„ìœ¼ë¡œ í”„ë ˆì„ ê°±ì‹ 
        self.timer = QTimer(self)
        self.timer.timeout.connect(self.update_frame)
        self.timer.start(20)  # 30msë§ˆë‹¤ í”„ë ˆì„ ê°±ì‹ 

    def initUI(self):
        self.setWindowTitle('ì°¨ëŸ‰ ë²ˆí˜¸íŒ ì¸ì‹ ì‹œìŠ¤í…œ')
        self.setGeometry(100, 100, 800, 600)

        # ì´ë¯¸ì§€ í‘œì‹œ ë¼ë²¨
        self.label_img = QLabel(self)
        self.label_img.setFixedSize(640, 480)

        # ë²ˆí˜¸íŒ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥
        self.list_plates = QListWidget(self)

        # ë ˆì´ì•„ì›ƒ ì„¤ì •
        layout = QVBoxLayout()
        layout.addWidget(self.label_img)
        layout.addWidget(self.list_plates)
        self.setLayout(layout)

    def update_frame(self):
        """íƒ€ì´ë¨¸ë¡œ ê°±ì‹ ë˜ëŠ” í”„ë ˆì„ ì²˜ë¦¬"""
        if self.thread.latest_frame is not None:
            plates, processed_img = self.detectLicensePlates(self.thread.latest_frame)
            self.displayImage(processed_img)
            self.displayPlates(plates)

    def update_image(self, frame):
        """ìŠ¤ë ˆë“œì—ì„œ ë°›ì€ í”„ë ˆì„ì„ ìµœì‹  í”„ë ˆì„ìœ¼ë¡œ ì—…ë°ì´íŠ¸"""
        self.thread.latest_frame = frame

    def detectLicensePlates(self, img):
        """ë²ˆí˜¸íŒ ì¸ì‹ ì²˜ë¦¬"""
        # YOLOv5ë¡œ ì°¨ëŸ‰ ê°ì§€
        results = self.model(img)
        cars_detected = []

        for *xyxy, conf, cls in results.xyxy[0]:
            if conf > 0.4 and int(cls) == 2:  # ì°¨ëŸ‰ í´ë˜ìŠ¤ (í´ë˜ìŠ¤ IDëŠ” ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
                x1, y1, x2, y2 = map(int, xyxy)
                cars_detected.append((x1, y1, x2, y2))
                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 3)
                cv2.putText(img, 'Car', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3, cv2.LINE_AA)

        # EasyOCRì„ ì´ìš©í•œ ë²ˆí˜¸íŒ ì¸ì‹
        THRESHOLD = 0.1
        plates_by_car = {i: [] for i in range(len(cars_detected))}  # ì°¨ëŸ‰ë³„ ë²ˆí˜¸íŒ ì €ì¥

        for bbox, text, conf in self.reader.readtext(img):
            if conf > THRESHOLD:
                x_text, y_text = bbox[0]  # ì¸ì‹ëœ í…ìŠ¤íŠ¸ì˜ ì¢Œí‘œ (ì¢Œì¸¡ ìƒë‹¨)

                # ğŸ”¹ í•œê¸€ê³¼ ìˆ«ìë§Œ í•„í„°ë§
                filtered_text = re.sub(r'[^ê°€-í£0-9]', '', text)

                if filtered_text:  # ìœ íš¨í•œ í…ìŠ¤íŠ¸ë§Œ ì²˜ë¦¬
                    for i, (x1, y1, x2, y2) in enumerate(cars_detected):
                        if x1 < x_text < x2 and y1 < y_text < y2:  # ì°¨ëŸ‰ ë‚´ë¶€ì˜ ë¬¸ìë§Œ ì¸ì‹
                            plates_by_car[i].append(filtered_text)
                            cv2.rectangle(img, tuple(map(int, bbox[0])), tuple(map(int, bbox[2])), (0, 255, 255), 3)

        # ìµœì¢… ë²ˆí˜¸íŒ ë¦¬ìŠ¤íŠ¸ ìƒì„± (ê° ì°¨ëŸ‰ë³„ë¡œ ë²ˆí˜¸íŒ ë¬¸ìì—´ í•©ì¹˜ê¸°)
        plates = []
        for i in range(len(cars_detected)):
            if plates_by_car[i]:  # ë²ˆí˜¸íŒì´ ì¸ì‹ëœ ê²½ìš°
                plate_number = "".join(plates_by_car[i])
                plates.append(plate_number)

        return plates, img



    def displayImage(self, img):
        """ì´ë¯¸ì§€ í‘œì‹œ"""
        if img is None:
            return

        # OpenCV ì´ë¯¸ì§€ â†’ QImage ë³€í™˜
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        height, width, channel = img.shape
        bytes_per_line = channel * width
        q_image = QImage(img.data, width, height, bytes_per_line, QImage.Format_RGB888)
        pixmap = QPixmap.fromImage(q_image)

        # QLabelì— ì´ë¯¸ì§€ ì„¤ì •
        self.label_img.setPixmap(pixmap)
        self.label_img.setScaledContents(True)

    def displayPlates(self, plates):
        """ë²ˆí˜¸íŒ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥"""
        self.list_plates.clear()
        for idx, plate in enumerate(plates):
            self.list_plates.addItem(f"ì°¨ëŸ‰ {idx + 1} ë²ˆí˜¸íŒ: {plate}")

    def closeEvent(self, event):
        """ìœˆë„ìš° ë‹«ì„ ë•Œ ì¹´ë©”ë¼ ë¦¬ì†ŒìŠ¤ í•´ì œ"""
        self.cap.release()
        self.thread.quit()
        event.accept()


class VideoCaptureThread(QThread):
    change_pixmap_signal = pyqtSignal(np.ndarray)

    def __init__(self, cap):
        super().__init__()
        self.cap = cap
        self.latest_frame = None

    def run(self):
        """ë¹„ë””ì˜¤ ìº¡ì²˜ ë° í”„ë ˆì„ ì†¡ì¶œ"""
        while True:
            ret, frame = self.cap.read()
            if ret:
                self.latest_frame = frame
                self.change_pixmap_signal.emit(frame)


if __name__ == '__main__':
    app = QApplication(sys.argv)
    window = LicensePlateRecognitionApp()
    window.show()
    sys.exit(app.exec_())
